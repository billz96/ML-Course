{"cells":[{"metadata":{},"cell_type":"markdown","source":"Η ΣΕΙΡΑ ΑΠΑΝΤΗΣΗΣ ΕΙΝΑΙ ΕΡΩΤΗΜΑ 2, ΕΡΩΤΗΜΑ 3, ΕΡΩΤΗΜΑ 1\nΟΜΩς Η ΠΡΟΕΤΟΙΜΑΣΙΑ ΤΩΝ ΠΙΝΑΚΩΝ ΤΩΝ ΧΑΡΑΚΤΗΡΙΣΤΙΚΩΝ ΓΊΝΕΤΑΙ ΜΕ ΕΝΙΑΊΟ ΤΡΟΠΟ\n\nΤΟ DO για να τελειώσει η εργασία\n* ΘΕΜΑ 1\nΝα επαναληφθει για τις άλλες 2 εταιρίες για να βρεθει η εταιρεία με την μεγαλύτερη ακρίβεια ταξινόμησης με την μέθοδο της 10πλης διεπικήρωσης (10fold validation) : το ερώτημα 1 (στο τελος του notebook) εχει k fold validation αλλα δεν καταλαβαινω αν ειναι σεταρισμένο / ενεργοποιημένο.\n* ΘΕΜΑ 2\nΝα επαναληφθει για τις άλλες 2 εταιρίες για να βρεθει η εταιρεία με την μεγαλύτερη ακρίβεια ταξινόμησης με την μέθοδο της 10πλης διεπικήρωσης (10fold validation) ->>ΒΗΜΑ 15 https://machinelearningmastery.com/k-fold-cross-validation/ ή https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6 OK\n* ΘΕΜΑ 3\nΝα γίνει οπως το 2 με επιπλέον χαρακτηριστικά:\nτα γκολ της μιας, τα γκολ της αλλης, τα προγνωστικά για όλες τις εταιρίες OK"},{"metadata":{},"cell_type":"markdown","source":"Gm(h) -> γκολ μιας ομαδας που επαιζε εντος εδρας\n\nGm(a) -> γκολ μιας ομαδας που επαιζε εκτος εδρας\n\nΤ = {t1, t2, ..., tk} -> κ πληθους ομαδες \n\nΜ = {m1, m2, ..., mj} -> j πληθους αγωνες\n\nr μια συναρτηση που το αποτελεσμα της ανηκει στο συνολο {H, D, A} -> αποτελεσμα αγωνα\nr(match, home_team, away_team) = {\n    return H if DGm(home_team, away_team) > 0\n    return D if DGm(home_team, away_team) = 0\n    return A if DGm(home_team, away_team) < 0\n}\n\nDGm(home_team, away_team) = Gm(h) - Gm(a)\n\nR2 -> (x, y)\nR8 -> (x1, x2, x3, ... x8)\nRn -> (x1, x2, x3, ..., xn)\nf(t) ανηκει στο συνολο R8 και η μεταβλητη  t ειναι μια ομαδα απο το συνολο T\n\nk ανηκει στο συνολο {Β365, BW, IW, LB} -> εταιριες\n\nψ(match) -> αποδοσεις για καθε πιθανο αποτελεσμα απο τις κ εταιριες (ειναι ενα τετραδα της μορφης: (a, b, c, d))\n \n \n "},{"metadata":{"_cell_guid":"adb0c08c-1a70-dee0-f86e-246efaf5aa35","trusted":true},"cell_type":"code","source":"# Δες αν υπάρχει η βάση στον φακελο\n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport sqlite3 as sq\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input/soccer\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"% Create a connection to the database.\n% Retrieve the contents of the Team_Attributes table containing the\n% following columns: id,\n% Retrieve the contents of the Match table containing the following\n% columns: id, B365H, B365D, B365A,BWH, BWD, BWA, IWH, IWD, IWA, LBH, LBD, LBA\nand collumns needed to calculate game result and teams ids"},{"metadata":{"_cell_guid":"f18da71b-0594-9e6e-c8a0-81bc6c4479c4","trusted":true},"cell_type":"code","source":"# γεμισε τους πίνακες team_att (χαρακτ ομάδας), match (προγνωστικά και αποτελέσματα)\nimport xml.etree.ElementTree as ET\nfrom copy import copy\n\n\n\n#just reading data\ncon = sq.connect(\"../input/soccer/database.sqlite\")\nteam_att = pd.read_sql_query(\"SELECT * from Team_Attributes\", con)\nteam_att = team_att [['id','team_api_id','buildUpPlaySpeed','buildUpPlayPassing','chanceCreationPassing','chanceCreationCrossing','chanceCreationShooting','defencePressure','defenceAggression','defenceTeamWidth']]\nteam = pd.read_sql_query(\"SELECT * from Team\", con)\nmatch = pd.read_sql_query(\"SELECT * from Match\", con)\n#for col in match.columns: \n#    print(col) \n# all preditind companies: \n#R28 = match[['goal', 'shoton', 'shotoff', 'foulcommit', 'card', 'cross', 'corner', 'possession']]\n#match = match[['id','match_api_id','home_team_api_id', 'home_team_goal', 'away_team_goal','away_team_api_id','B365H', 'B365D', 'B365A', 'BWH', 'BWD', 'BWA', 'IWH', 'IWD', 'IWA', 'LBH', 'LBD',\n#              'LBA']]\n\n#R28.mask(R28.astype(object).eq('None')).dropna()\n##for row in R28.loc[1728]:\n#    print(type(row))\n#    print(\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"show match"},{"metadata":{"_cell_guid":"835340aa-2788-acc0-ecb0-65c4d290ea3c","trusted":true},"cell_type":"code","source":"match","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#clean match from empties"},{"metadata":{"trusted":true},"cell_type":"code","source":"match.dropna()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"add columns home_win, away_win, draw με 0 ή 1 με βαση ποια ομαδα εβαλε τα περισσότερα goals"},{"metadata":{"trusted":true},"cell_type":"code","source":"match.loc[(match['home_team_goal'] > match['away_team_goal']),'home_win']= int('1')\nmatch.loc[(match['home_team_goal'] < match['away_team_goal']),'away_win']= int('1')\nmatch.loc[(match['home_team_goal'] == match['away_team_goal']),'draw']= int('1')\nmatch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# replace NaN with 0\nmatch.fillna(0, inplace=True)\nmatch","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mετατροπη των αποδόσεων σε προτεινόμενες πιθανότητες (implied probabilities). Έτσι έχουμε εύρος απο 0 εως 1 για όλα τα χαρακτηριστικά."},{"metadata":{"trusted":true},"cell_type":"code","source":"# κανω drop τις σειρες που εχουν odds 0.00\n\n#match[(match.T !=0).any()]\nmatch = match[match.B365H != 0]\nmatch = match[match.BWH != 0]\nmatch = match[match.IWD != 0]\nmatch = match[match.LBH != 0]\n# match\nmatch2=match\n\nmatch2['B365H'] = 1/match['B365H']\nmatch2['B365D'] = 1/match['B365D']\nmatch2['B365A'] = 1/match['B365A']\nmatch2['BWH'] = 1/match['BWH']\nmatch2['BWD'] = 1/match['BWD']\nmatch2['BWA'] = 1/match['BWA']\nmatch2['IWH'] = 1/match['IWH']\nmatch2['IWD'] = 1/match['IWD']\nmatch2['IWA'] = 1/match['IWA']\nmatch2['LBH'] = 1/match['LBH']\nmatch2['LBD'] = 1/match['LBD']\nmatch2['LBA'] = 1/match['LBA']\nmatch2\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#match2.replace([np.inf, -np.inf], np.nan)\n#match2.dropna","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ο πίνακας team_att περιέχει τα 8 χαρακτηριστικά κάθε ομάδας, όπως χρειάζονται για το ερώτημα 3"},{"metadata":{"trusted":true},"cell_type":"code","source":"team_att","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Για το ερώτημα 3 φτιάχνω ενα join table απο τα match και team_att με βαση home_team_api_id\taway_team_api_id, επίσης κρατάω μόνο τα προγνωστικά για τις 4 εταιρίες\n# ενδιαμεσοι πίνακες για καθε ομαδα με τα χαρακτηριστικά τους\nteam_att.rename(columns = {'team_api_id':'home_team_api_id'}, inplace = True)\n#away_team_att = team_att.rename(columns = {'home_team_api_id':'away_team_api_id'}, inplace = True)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Κάνω JOIN τους πίνακες team_att και match με βάση το κλειδι team_api_id = home_team_api_id, και επίσης για το team_api_id = away_team_api_id"},{"metadata":{"trusted":true},"cell_type":"code","source":"match2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"team_att","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Βλέπουμε οτι επαναλαμβάνονται οι εμφανίσεις των ίδιων χαρακτηριστικών (εξελίσονται στον χρόνο) οπότε επιλέγουμε να χρησιμοποιήσουμε το mean των εκάστοτε χαρακτηριστικών με για κάθε ομάδα"},{"metadata":{"trusted":true},"cell_type":"code","source":"team_att2=team_att.groupby(['home_team_api_id']).agg({'buildUpPlaySpeed':'mean','buildUpPlayPassing':'mean','chanceCreationPassing':'mean','chanceCreationCrossing':'mean','chanceCreationShooting':'mean','defencePressure':'mean','defenceAggression':'mean','defenceTeamWidth':'mean'})\n#team_att2=team_att2.groupby(['home_team_api_id']).agg({'buildUpPlaySpeed':'mean','buildUpPlayPassing':'mean','chanceCreationPassing':'mean','chanceCreationCrossing':'mean','chanceCreationShooting':'mean','defencePressure':'mean','defenceAggression':'mean','defenceTeamWidth':'mean'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"team_att","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"..και κανουμε merge τα χαρακτηριστικά με τα odds"},{"metadata":{"trusted":true},"cell_type":"code","source":"q3 = pd.merge(match2, team_att2, on=['home_team_api_id'])\n#q3 = pd.merge(match2, away_team_att, on=['away_team_api_id'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q3 = pd.merge(match2, team_att2, on=['home_team_api_id'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q3= q3.rename(columns={'buildUpPlaySpeed': 'home_buildUpPlaySpeed', 'buildUpPlayPassing': 'home_buildUpPlayPassing','chanceCreationPassing': 'home_chanceCreationPassing', 'chanceCreationCrossing': 'home_chanceCreationCrossing','chanceCreationShooting': 'home_chanceCreationShooting', 'defencePressure': 'home_defencePressure','defenceAggression': 'home_defenceAggression', 'defenceTeamWidth': 'home_defenceTeamWidth'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q3 # O Πίνακας με τα χαρακτηρισιτκά εισαγωγής για το ερώτημα 3 (TNN με 28 χαρακτ)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"team_att","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Εισαγω στον γενικό πίνακα τα χαρακτηριστικά της home team ( με join )"},{"metadata":{"trusted":true},"cell_type":"code","source":"team_att.rename(columns = {'team_api_id':'away_team_api_id'}, inplace = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"team_att=team_att.groupby(['home_team_api_id']).agg({'buildUpPlaySpeed':'mean','buildUpPlayPassing':'mean','chanceCreationPassing':'mean','chanceCreationCrossing':'mean','chanceCreationShooting':'mean','defencePressure':'mean','defenceAggression':'mean','defenceTeamWidth':'mean'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"team_att.index.names = ['away_team_api_id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"team_att","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"team_att = team_att.rename(columns={'buildUpPlaySpeed': 'away_buildUpPlaySpeed', 'buildUpPlayPassing': 'away_buildUpPlayPassing','chanceCreationPassing': 'away_chanceCreationPassing', 'chanceCreationCrossing': 'away_chanceCreationCrossing','chanceCreationShooting': 'away_chanceCreationShooting', 'defencePressure': 'away_defencePressure','defenceAggression': 'away_defenceAggression', 'defenceTeamWidth': 'away_defenceTeamWidth'})\n#team_att.rename(columns = {'home_team_api_id':'away_team_api_id'}, inplace = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"team_att","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q3 = pd.merge(match2, team_att, on=['away_team_api_id'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"team_att2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q3 = pd.merge(match2, team_att2, on=['home_team_api_id'])\nq3 = pd.merge(q3, team_att, on=['away_team_api_id'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q3.loc[(q3['home_win'] == 1.0),'result'] = 1 #swsto\nq3.loc[(q3['away_win'] == 1.0),'result'] = 2\nq3.loc[(q3['draw'] == 1.0),'result'] = 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q3 = q3.dropna() #swsto\n\nq3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> O πίνακας  deep_attrib έχει μόνο τις στήλες που χρειαζόμαστε, υποσύνολο του q3"},{"metadata":{"trusted":true},"cell_type":"code","source":"deep_attrib = q3[['B365H','B365D','B365A','BWH','BWD','BWA','IWH','IWD','IWA','LBH','LBD','LBA','buildUpPlaySpeed','buildUpPlayPassing','chanceCreationPassing','chanceCreationCrossing','chanceCreationShooting','defencePressure','defenceAggression','defenceTeamWidth','away_buildUpPlaySpeed','away_buildUpPlayPassing','away_chanceCreationPassing','away_chanceCreationCrossing','away_chanceCreationShooting','away_defencePressure','away_defenceAggression','away_defenceTeamWidth','result']].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"deep_attrib","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f7dc5562-80cd-13d0-c211-79228f94e592","trusted":true},"cell_type":"code","source":"team_att","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# γραμμικο νευρωνικο \n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2dab2cac-2ebe-50ea-05a4-772485838734","trusted":true},"cell_type":"code","source":"#shuffle match rows so split tables are randomized\n#match = match.reindex(np.random.permutation(match.index))\n\n#split match data into training, validation, and test sets\nm_train = match.iloc[:17861]\nm_valid = match.iloc[17861:21108]\nm_test = match.iloc[21108:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"--ΑΛΛΑΓΗ ΤΟ ΠΑΡΑΚΑΤΩ ΣΕ ΕΛΛΗΝΙΚΑ---\n\nWe take one company data only + classes, put it in X array\nWe need to grab the data (the information on each sample) from the pandas array and put it into a nice numpy one.\n\nX=match[['column1','column2','column3'....]]\nX = np.array(X)\nX[:5]\n\nclasses are already hot encoded (1,0,0).. for home win.. \nwe have to put classes in Y\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=match2[['B365H','B365D','B365A']]\nX = np.array(X)\nY=match2[['home_win','away_win','draw']]\nY=np.array(Y)\nX[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next we will split our dataset into train/validation/test using sklearn. Initially the data will be split into train/test and then the training data will be further split into train/validation."},{"metadata":{"trusted":true},"cell_type":"markdown","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15)\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1)"},{"metadata":{},"cell_type":"markdown","source":"we are going to build a simple neural network that supports multiple layers and validation. The main function is NeuralNetwork, which will train the network for the specified number of epochs. At first, the weights of the network will get randomly initialized by InitializeWeights. Then, in each epoch, the weights will be updated by Train and finally, every 20 epochs accuracy both for the training and validation sets will be printed by the Accuracy function. As input the function receives the following:\n\nX_train, Y_train: The training data and target values.\nX_val, Y_val: The validation data and target values. These are optional parameters.\nepochs: Number of epochs. Defaults at 10.\nnodes: A list of integers. Each integer denotes the number of nodes in each layer. The length of this list denotes the number of layers. That is, each integer in this list corresponds to the number of nodes in each layer.\nlr: The learning rate of the back-propagation training algorithm. Defaults at 0.15."},{"metadata":{"trusted":true},"cell_type":"markdown","source":"def NeuralNetwork(X_train, Y_train, X_val=None, Y_val=None, epochs=2, nodes=[], lr=0.15):\n    hidden_layers = len(nodes) - 1\n    weights = InitializeWeights(nodes)\n\n    for epoch in range(1, epochs+1):\n        weights = Train(X_train, Y_train, lr, weights)\n        \n        print(\"epoch = {}\".format(epoch))\n        print(\"Training Accuracy:{}\".format(Accuracy(X_train, Y_train, weights)))\n        if X_val.any():\n                print(\"Validation Accuracy:{}\".format(Accuracy(X_val, Y_val, weights)))\n        \n        #if(epoch % 20 == 0):\n        #    print(\"Epoch {}\".format(epoch))\n        #    print(\"Training Accuracy:{}\".format(Accuracy(X_train, Y_train, weights)))\n        #    if X_val.any():\n        #        print(\"Validation Accuracy:{}\".format(Accuracy(X_val, Y_val, weights)))\n            \n    return weights"},{"metadata":{},"cell_type":"markdown","source":"The weights of the network are initialized randomly in the range [-1, 1] by InitializeWeights. This function takes as input nodes and returns a multi-dimensional array, weights. Each element in the weights list represents a hidden layer and holds the weights of connections from the previous layer (including the bias) to the current layer. So, element i in weights holds the weights of the connections from layer i-1 to layer i. Note that the input layer has no incoming connections so it is not present in weights.\n\nFor example, let's say we have four features (as is the case with the Iris dataset) and the hidden layers have 5, 10 and 3 (for the output, one for each class) nodes. Thus, nodes == [4, 5, 10, 3] Then, the connections between the input layer and the first hidden layer will be (4+1)*5 = 25. After augmenting the input with the bias (in this case the bias has a constant value of 1), the input layer has 5 nodes. By fully connecting this layer to the next (each node in the input layer is connected will every node of the hidden layer), we get that the total number of connections is 25. Similarly, we get that the connections between the first hidden layer and the second one will be (5+1)*10 = 60 and between the second hidden layer with the output we have (10+1)*3 = 33 connections.\n\nIn the implementation, numpy is used to generate a random number in the [-1, 1] range for each connection."},{"metadata":{"trusted":true},"cell_type":"markdown","source":"def InitializeWeights(nodes):\n    \"\"\"Initialize weights with random values in [-1, 1] (including bias)\"\"\"\n    layers, weights = len(nodes), []\n    \n    for i in range(1, layers):\n        w = [[np.random.uniform(-1, 1) for k in range(nodes[i-1] + 1)]\n              for j in range(nodes[i])]\n        weights.append(np.matrix(w))\n    \n    return weights"},{"metadata":{},"cell_type":"markdown","source":"With the weights of the network at hand, we want to continuously adjust them across the epochs so that (hopefully) our network becomes more accurate. The training of the weights is accomplished via the popular (Forward) Back-Propagation algorithm. In this technique, the input first passes through the whole network and the output is calculated. Then, according to the error of this output, the weights of the network are updated from last to first. The error is propagated backwards, hence the name of the titular algorithm. Let's get into more detail about these two steps:\n\nForward Propagation:\n\nEach layer receives an input and computes an output. The output is computed by first calculating the dot product between the input and the weights of the layer and then passing this dot product through an activation function (in this case, the sigmoid function).\nThe output of each layer is the input of the next.\nThe input of the first layer is the feature vector.\nThe output of the final layer is the prediction of the network."},{"metadata":{"trusted":true},"cell_type":"markdown","source":"def ForwardPropagation(x, weights, layers):\n    activations, layer_input = [x], x\n    for j in range(layers):\n        activation = Sigmoid(np.dot(layer_input, weights[j].T))\n        activations.append(activation)\n        layer_input = np.append(1, activation) # Augment with bias\n    \n    return activations"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"def BackPropagation(y, activations, weights, layers):\n    outputFinal = activations[-1]\n    error = np.matrix(y - outputFinal) # Error at output\n    \n    for j in range(layers, 0, -1):\n        currActivation = activations[j]\n        \n        if(j > 1):\n            # Augment previous activation\n            prevActivation = np.append(1, activations[j-1])\n        else:\n            # First hidden layer, prevActivation is input (without bias)\n            prevActivation = activations[0]\n        \n        delta = np.multiply(error, SigmoidDerivative(currActivation))\n        weights[j-1] += lr * np.multiply(delta.T, prevActivation)\n\n        w = np.delete(weights[j-1], [0], axis=1) # Remove bias from weights\n        error = np.dot(delta, w) # Calculate error for current layer\n    \n    return weights"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"    def Train(X, Y, lr, weights):\n        layers = len(weights)\n        for i in range(len(X)):\n            x, y = X[i], Y[i]\n            x = np.matrix(np.append(1, x)) # Augment feature vector\n        \n            activations = ForwardPropagation(x, weights, layers)\n            weights = BackPropagation(y, activations, weights, layers)\n\n        return weights"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"def Sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n\ndef SigmoidDerivative(x):\n    return np.multiply(x, 1-x)"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"def Predict(item, weights):\n    layers = len(weights)\n    item = np.append(1, item) # Augment feature vector\n    \n    ##_Forward Propagation_##\n    activations = ForwardPropagation(item, weights, layers)\n    \n    outputFinal = activations[-1].A1\n    index = FindMaxActivation(outputFinal)\n\n    # Initialize prediction vector to zeros\n    y = [0 for i in range(len(outputFinal))]\n    y[index] = 1  # Set guessed class to 1\n\n    return y # Return prediction vector\n\n\ndef FindMaxActivation(output):\n    \"\"\"Find max activation in output\"\"\"\n    m, index = output[0], 0\n    for i in range(1, len(output)):\n        if(output[i] > m):\n            m, index = output[i], i\n    \n    return index"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"def Accuracy(X, Y, weights):\n    \"\"\"Run set through network, find overall accuracy\"\"\"\n    correct = 0\n\n    for i in range(len(X)):\n        x, y = X[i], list(Y[i])\n        guess = Predict(x, weights)\n\n        if(y == guess):\n            # Guessed correctly\n            correct += 1\n\n    return correct / len(X)"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"f = len(X[0]) # Number of features\no = len(Y[0]) # Number of outputs / classes\n\nlayers = [f, 5, 10, o] # Number of nodes in layers\nlr, epochs = 0.15, 10 #100\n\nweights = NeuralNetwork(X_train, Y_train, X_val, Y_val, epochs=epochs, nodes=layers, lr=lr);"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"print(\"Testing Accuracy: {}\".format(Accuracy(X_test, Y_test, weights)))"},{"metadata":{},"cell_type":"markdown","source":"Testing Accuracy: 0.5143874221299318 me 20 epochs 0.15 step"},{"metadata":{},"cell_type":"markdown","source":"Enalaktikos kwdikos gia deep nn me k-fold validation (ΕΡΩΤΗΜΑ 2)"},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ΦΤΙΑΧΝΩ 4 ΠΙΝΑΚΕΣ ΠΟΥ ΠΕΡΙΈΧΟΥΝ ΤΑ ΠΡΟΓΝΩΣΤΙΚΆ ΚΑΙ ΤΑ ΑΠΟΤΕΛΕΣΜΑΤΑ - ΕΝΑΝ ΠΙΝΑΚΑ ΓΙΑ ΚΑΘΕ ΕΤΑΙΡΙΑ"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n# companies = 'B365H','B365D','B365A', 'BWH','BWD','BWA', 'IWH','IWD','IWA', 'LBH','LBD','LBA'\npd.options.mode.chained_assignment = None  # default='warn'\nmatchB365 = match[[\"B365H\",\"B365A\",\"B365D\",\"home_team_goal\",\"away_team_goal\"]]\nmatchB365[\"result\"]= np.nan\n\nmatchBW =  match[['BWH','BWD','BWA',\"home_team_goal\",\"away_team_goal\"]]\nmatchBW[\"result\"]= np.nan\n\nmatchIW =  match[['IWH','IWD','IWA',\"home_team_goal\",\"away_team_goal\"]]\nmatchIW[\"result\"]= np.nan\n\nmatchLB =  match[['LBH','LBD','LBA',\"home_team_goal\",\"away_team_goal\"]]\nmatchLB[\"result\"]= np.nan\n\n#matchB365.loc[:, 'result'] = 0\nmatchB365","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matchB365.loc[(matchB365['home_team_goal'] > matchB365['away_team_goal']),'result']= int('1')\nmatchB365.loc[(matchB365['home_team_goal'] < matchB365['away_team_goal']),'result']= int('2')\nmatchB365.loc[(matchB365['home_team_goal'] == matchB365['away_team_goal']),'result']= int('3')\n#matchB365['result'] = np.where(matchB365['home_win']== '1.0', True, False)\nmatchB365 = matchB365[[\"B365H\",\"B365A\",\"B365D\",\"result\"]]\n\nmatchBW[\"result\"] = matchB365[\"result\"].values\nmatchIW[\"result\"]= matchB365[\"result\"].values\nmatchLB[\"result\"]= matchB365[\"result\"].values\n\nmatchB365","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matchIW","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#matchB365.loc[(matchB365['home_team_goal'] = '1.0'),'result']= int('1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#matchB365[\"result\"] = np.where((matchB365.home_win=\"1.0\"),true,false)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matchBW","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matchB365=matchB365.to_numpy()\nmatchBW=matchBW.to_numpy()\nmatchIW=matchIW.to_numpy()\nmatchLB=matchLB.to_numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matchB365","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y=matchB365[:,3]\nYBW=matchBW[:,3]\nYIW=matchIW[:,3]\nYLB=matchLB[:,3]\n\nY.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ΧΩΡΙΖΩ ΤΟΝ ΚΑΘΕ ΠΙΝΑΚΑ ΣΕ ΠΡΟΓΝΩΣΤΙΚΑ ΚΑΙ ΑΠΟΤΕΛΕΣΜΑ για τα Ερωτήματα 1 και 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=matchB365[:,0:2]\nY=matchB365[:,3]\n\nXBW=matchBW[:,0:2]\nYBW=matchBW[:,5]\n\nXIW=matchIW[:,0:2]\nYIW=matchIW[:,5]\n\nXLB=matchLB[:,0:2]\nYLB=matchLB[:,5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X=X.to_numpy()\n#Y=Y.to_numpy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ερώτημα 2\n# Αρχίζουμε την εκπαίδευση του πολυστρωματικού νευρωνικού δικτύου (3 χαρακτηριστικά / εταιρεία)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import KFold\nfrom sklearn.neural_network import MLPClassifier\n\n#f = open(\"seeds_dataset.txt\")\n#data = np.loadtxt(f)\n\n\nkf = KFold(n_splits=10)\nclf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(3, 28), random_state=1,max_iter=900) #hidden_layer_sizes=(samples=results ,features)\n\n'buildUpPlaySpeed','buildUpPlayPassing','chanceCreationPassing','chanceCreationCrossing','chanceCreationShooting','defencePressure','defenceAggression','defenceTeamWidth','away_buildUpPlaySpeed','away_buildUpPlayPassing','away_chanceCreationPassing','away_chanceCreationCrossing','away_chanceCreationShooting','away_defencePressure','away_defenceAggression','away_defenceTeamWidth'\n\nmeanB365 = 0\nfor train_indices, test_indices in kf.split(X):\n    clf.fit(X[train_indices], Y[train_indices])\n    print(clf.predict(X[test_indices]))\n    current_score = clf.score(X[test_indices], Y[test_indices])\n    print(current_score)\n    meanB365 += current_score\nmeanB365 = meanB365 / 10\nprint(\"average score for B365 is: {}\".format(meanB365))\nprint(\"\")\n\nkf2 = KFold(n_splits=10)\nclf2 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(3, 28), random_state=1,max_iter=900) #hidden_layer_sizes=(samples=results ,features)\n\n'buildUpPlaySpeed','buildUpPlayPassing','chanceCreationPassing','chanceCreationCrossing','chanceCreationShooting','defencePressure','defenceAggression','defenceTeamWidth','away_buildUpPlaySpeed','away_buildUpPlayPassing','away_chanceCreationPassing','away_chanceCreationCrossing','away_chanceCreationShooting','away_defencePressure','away_defenceAggression','away_defenceTeamWidth'\n\nmeanBW = 0\nfor train_indices, test_indices in kf2.split(XBW):\n    clf2.fit(XBW[train_indices], YBW[train_indices])\n    print(clf2.predict(XBW[test_indices]))\n    current_score = clf2.score(XBW[test_indices], YBW[test_indices])\n    print(current_score)\n    meanBW += current_score\nmeanBW = meanBW / 10\nprint(\"average score for BW is: {}\".format(meanBW))\nprint(\"\")\n\nkf3 = KFold(n_splits=10)\nclf3 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(3, 28), random_state=1,max_iter=900) #hidden_layer_sizes=(samples=results ,features)\n\n'buildUpPlaySpeed','buildUpPlayPassing','chanceCreationPassing','chanceCreationCrossing','chanceCreationShooting','defencePressure','defenceAggression','defenceTeamWidth','away_buildUpPlaySpeed','away_buildUpPlayPassing','away_chanceCreationPassing','away_chanceCreationCrossing','away_chanceCreationShooting','away_defencePressure','away_defenceAggression','away_defenceTeamWidth'\n\nmeanLW = 0\nfor train_indices, test_indices in kf3.split(XIW):\n    clf3.fit(XIW[train_indices], YIW[train_indices])\n    print(clf3.predict(XIW[test_indices]))\n    current_score = clf3.score(XIW[test_indices], YIW[test_indices])\n    print(current_score)\n    meanLW += current_score\nmeanLW = meanLW / 10\nprint(\"average score for LW is: {}\".format(meanLW))\nprint(\"\")\n\nkf4 = KFold(n_splits=10)\nclf4 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(3, 28), random_state=1,max_iter=900) #hidden_layer_sizes=(samples=results ,features)\n\n'buildUpPlaySpeed','buildUpPlayPassing','chanceCreationPassing','chanceCreationCrossing','chanceCreationShooting','defencePressure','defenceAggression','defenceTeamWidth','away_buildUpPlaySpeed','away_buildUpPlayPassing','away_chanceCreationPassing','away_chanceCreationCrossing','away_chanceCreationShooting','away_defencePressure','away_defenceAggression','away_defenceTeamWidth'\n\nmeanLB = 0\nfor train_indices, test_indices in kf4.split(XLB):\n    clf4.fit(XLB[train_indices], YLB[train_indices])\n    print(clf4.predict(XLB[test_indices]))\n    current_score = clf4.score(XLB[test_indices], YLB[test_indices])\n    print(current_score)\n    meanLB += current_score\nmeanLB = meanLB / 10\nprint(\"average score for LB is: {}\".format(meanLB))\nprint(\"\")\n\nmeanDict = {meanB365:\"B365\", meanBW:\"BW\", meanLW:\"LW\", meanLB:\"LB\"}\ncompany_mean = max([meanB365, meanBW, meanLW, meanLB])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"max average is for company : {}\".format(meanDict[company_mean]))\nmeanDict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ΕΡΩΤΗΜΑ 3\n\n(Εχουμε φτιαξει απο πριν τον πίνακα deep_attrib με τα απαραίτητα χαρακτηριστικά ν=28 που είναι τα odds απο 4 εταιρίες, και τα 8 χαρακτηριστικά απο κάθε ομάδα)"},{"metadata":{"trusted":true},"cell_type":"code","source":"X3 = deep_attrib.to_numpy()\nX3= X3[:,0:28]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y3 = deep_attrib.to_numpy()\nY3 = Y3[:,28]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Φτιαχνουμε ενα δίκτυο Multi-layer Perceptron"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import KFold\nfrom sklearn.neural_network import MLPClassifier\n\n#f = open(\"seeds_dataset.txt\")\n#data = np.loadtxt(f)\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX3 = sc.fit_transform(X3)\n\n#https://scikit-learn.org/stable/modules/grid_search.html\n\nkf2 = KFold(n_splits=10)\nclf2 = MLPClassifier(solver='adam', activation ='relu', alpha=1e-5, hidden_layer_sizes=(5, 28), random_state=1,max_iter=1000,learning_rate_init=.1) # hidden_layer_sizes=(5, 28),\nfor train_indices, test_indices in kf2.split(X3):\n    clf2.fit(X3[train_indices], Y3[train_indices])\n   # print(clf2.predict_proba(X3[test_indices]))\n    print(clf2.score(X3[test_indices], Y3[test_indices]))\n    print(clf2.predict(X3[train_indices]))\n    print(clf2.predict(X3[test_indices]))\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"diagrams and attributed for trainning https://www.python-course.eu/neural_networks_with_scikit.php"},{"metadata":{},"cell_type":"markdown","source":"https://www.kaggle.com/ahmethamzaemra/mlpclassifier-example"},{"metadata":{},"cell_type":"markdown","source":"-------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"# **Ερωτημα 1**\n\nΓραμμικο μονοστρωματικο δικτυο. προσωρινα κανω export το dataframe σε csv. Ο κωδικάς του δεν θελει one hot για τα labels αλλα ονομα, οπότε πρεπει να φτιάξω στηλη με label-classes: home/away/draw αναλογα μετα αποτελεσματα.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ERWTIMA 1\nmatch2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ERWTIMA 1\nmatch.loc[(match['home_win'] == 1),'result']= 'home_win'\nmatch.loc[(match['away_win'] == 1),'result']= 'away_win'\nmatch.loc[(match['draw'] == 1),'result']= 'draw'\nmatch.loc[(match['home_team_goal'] > match['away_team_goal']),'home_win']= int('1')\nmatch.loc[(match['home_team_goal'] < match['away_team_goal']),'away_win']= int('1')\nmatch.loc[(match['home_team_goal'] == match['away_team_goal']),'draw']= int('1')\nmatch = match2[match2.result != 0]\n\nperceptronB365 = match[['B365H', 'B365D', 'B365A','result']]\nperceptronB365 = perceptronB365[perceptronB365.result != 0]\nperceptronB365 = perceptronB365[perceptronB365.B365H != 0]\nperceptronB365 = perceptronB365[perceptronB365.B365D != 0]\nperceptronB365 = perceptronB365[perceptronB365.B365A != 0]\n\nperceptronIW = match[['IWH', 'IWD', 'IWA','result']]\nperceptronIW = perceptronIW[perceptronIW.result != 0]\nperceptronIW = perceptronIW[perceptronIW.IWH != 0]\nperceptronIW = perceptronIW[perceptronIW.IWD != 0]\nperceptronIW = perceptronIW[perceptronIW.IWA != 0]\n\nperceptronLB = match[['LBH', 'LBD', 'LBA','result']]\nperceptronLB = perceptronLB[perceptronLB.result != 0]\nperceptronLB = perceptronLB[perceptronLB.LBH != 0]\nperceptronLB = perceptronLB[perceptronLB.LBD != 0]\nperceptronLB = perceptronLB[perceptronLB.LBA != 0]\n\nperceptronBW = match[['BWH', 'BWD', 'BWA','result']]\nperceptronBW = perceptronBW[perceptronBW.result != 0]\nperceptronBW = perceptronBW[perceptronBW.BWH != 0]\nperceptronBW = perceptronBW[perceptronBW.BWD != 0]\nperceptronBW = perceptronBW[perceptronBW.BWA != 0]\n\nperceptronB365.fillna('home_win', inplace=True)\nperceptronB365.to_csv(r'soccer_data_perceptronB365.csv', index = False)\n\nperceptronIW.fillna('home_win', inplace=True)\nperceptronIW.to_csv(r'soccer_data_perceptronIW.csv', index = False)\n\nperceptronLB.fillna('home_win', inplace=True)\nperceptronLB.to_csv(r'soccer_data_perceptronLB.csv', index = False)\n\nperceptronBW.fillna('home_win', inplace=True)\nperceptronBW.to_csv(r'soccer_data_perceptronBW.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ERWTIMA 1\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"/kaggle/working\"]).decode(\"utf8\"))\n#file = open(“soccer_data_perceptron.csv”,”r”) \n#print file.read() \nperceptronIW","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ERWTIMA 1\n\nimport math; #For pow and sqrt\nfrom random import shuffle;\n\n\n###_Read Data_###\ndef ReadData(fileName):\n    #Read the file, splitting by lines\n    f = open(fileName,'r');\n    lines = f.read().splitlines();\n    f.close();\n\n    #Split the first line by commas, remove the last element\n    #and save the length of the rest.\n    featuresNumber = len(lines[0].split(','));\n\n    items = [];\n    classes = [];\n    features = lines[0].split(',')[:-1];\n    print(features)\n\n    for i in range(1, len(lines)):\n        line = lines[i].split(',');\n\n        if(line[-1] not in classes):\n            classes.append(line[-1]);\n\n        itemFeatures = {\"Class\" : line[-1], \"Bias\" : 1};\n\n        for j in range(len(features)):\n            f = features[j]; #Get the feature at index j\n            v = float(line[j]);\n\n            itemFeatures[f] = v;\n    \n        items.append(itemFeatures);\n\n    shuffle(items);\n    \n    print(classes)\n\n    return items,classes,features;\n\n\n###_Evaluation Functions_###\ndef K_FoldValidation(K, Items, rate, epochs, classes, features):\n    if(K > len(Items)):\n        return -1;\n\n    correct = 0; #The number of correct classifications\n    total = len(Items)*(K-1); #The total number of classifications\n\n    l = int(len(Items)/K); #The length of a fold\n\n    for i in range(K):\n        #Split data set into training and testing\n        trainingSet = Items[i*l:(i+1)*l];\n        testSet = Items[:i*l] + Items[(i+1)*l:];\n\n        weights = CalculateWeights(trainingSet, rate, epochs, classes, features);\n\n        for item in testSet:\n            itemClass = item[\"Class\"];\n\n            itemFeatures = {};\n\n            for key in item:\n                if(key != \"Class\"):\n                    #If key isn't \"Class\", add it to itemFeatures\n                    itemFeatures[key] = item[key];\n          \n            guess = Perceptron(itemFeatures, weights);\n\n            if(guess == itemClass):\n                #Guessed correctly\n                correct += 1;\n\n    return correct/float(total);\n\ndef Evaluate(times, K, Items, rate, epochs, classes, features):\n    accuracy = 0;\n    for t in range(times):\n        shuffle(Items);\n        accuracy += K_FoldValidation(K, Items, rate, epochs, classes, features);\n    print(accuracy);\n    print((accuracy)/float(times)); # kai to % nomizw gia to upoloipo mias diairesis\n\n\n###_Auxiliary Functions_###\ndef AddDictionaries(d1, d2, rate):\n    d3 = {};\n    for i in d1:\n        d3[i] = d1[i] + rate*d2[i];\n\n    return d3;\n\ndef SubDictionaries(d1, d2, rate):\n    d3 = {};\n    for i in d1:\n        d3[i] = d1[i] - rate*d2[i];\n\n    return d3;\n\ndef CalculateConfidence(item, weight):\n    #Add the product of the weight and item values for each feature\n    confidence = 0;\n\n    for k in weight:\n        confidence += weight[k]*item[k];\n\n    return confidence;\n\n\n###_Core Functions_###\ndef CalculateWeights(trainingSet, rate, epochs, classes, features):\n    #Initialize weights at 0\n    weights = {};\n\n    #Initialize weights dictionary. Weights is divided in classes.\n    #Each class has its own dictionary, which is numerical values/weights\n    #for the features.\n    for c in classes:\n        weights[c] = {\"Bias\":0};\n        for f in features:\n            weights[c][f] = 0;\n\n    for epoch in range(epochs):\n        for item in trainingSet:\n            #Iterate through trainingSet\n            #Guess where item belongs\n            y = -1;\n            guess = \"\";\n            for w in weights:\n                confidence = CalculateConfidence(item, weights[w]);\n\n                if(confidence > y):\n                    y = confidence;\n                    guess = w;\n\n            correct = item[\"Class\"];\n            if(correct != guess):\n                weights[guess] = SubDictionaries(weights[guess], item, rate);\n                weights[correct] = AddDictionaries(weights[correct], item, rate);\n                \n    return weights;\n\ndef Perceptron(item, weights):\n    item[\"Bias\"] = 1; #Augment item vector with bias\n    m = -1; #Hold the maximum\n    classification = \"\";\n\n    #Calculate chance of item being in each class,\n    #pick the maximum.\n    for w in weights:\n        #Multiply the item vector with the class weights vector\n        guess = CalculateConfidence(item, weights[w]);\n        if(guess > m):\n            #Our guess is better than our current best guess,\n            #update max and classification\n            m = guess;\n            classification = w;\n\n    return classification;\n\n\nitemsB365, classesB365, featuresB365 = ReadData('/kaggle/working/soccer_data_perceptronB365.csv');\nitemsBW, classesBW, featuresBW = ReadData('/kaggle/working/soccer_data_perceptronBW.csv');\nitemsIW, classesIW, featuresIW = ReadData('/kaggle/working/soccer_data_perceptronIW.csv');\nitemsLB, classesLB, featuresLB = ReadData('/kaggle/working/soccer_data_perceptronLB.csv');\n    \nlRate = 0.1;\nepochs = 10;\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Τα αποτελέσματα χρησιμοποιόντας τα προγνωστικά της IW:\")\nweightsIW = CalculateWeights(itemsIW, lRate, epochs, classesIW, featuresIW);\nEvaluate(100, 10, itemsIW, lRate, epochs, classesIW, featuresIW);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Το αποτέλεσμα του παραπάνω\n\n['IWH', 'IWD', 'IWA']\n\n['draw', 'away_win', 'home_win']\n\n41.93545100715618\n\n0.4193545100715618\n\n**με 100 επαναλήψεις**\n\n42.093742427164784\n\n0.4209374242716478"},{"metadata":{},"cell_type":"markdown","source":"Τα αποτελέσματα χρησιμοποιόντας τα προγνωστικά της Bwin:"},{"metadata":{"trusted":true},"cell_type":"code","source":"weightsBW = CalculateWeights(itemsBW, lRate, epochs, classesBW, featuresBW);\nEvaluate(100, 10, itemsBW, lRate, epochs, classesBW, featuresBW);\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Τα αποτελέσματα χρησιμοποιόντας τα προγνωστικά της B365:"},{"metadata":{"trusted":true},"cell_type":"code","source":"weightsB365 = CalculateWeights(itemsB365, lRate, epochs, classesB365, featuresB365);\nEvaluate(100, 10, itemsB365, lRate, epochs, classesB365, featuresB365);\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Τα αποτελέσματα χρησιμοποιόντας τα προγνωστικά της LB:"},{"metadata":{"trusted":true},"cell_type":"code","source":"weightsLB = CalculateWeights(itemsLB, lRate, epochs, classesLB, featuresLB);\nEvaluate(100, 10, itemsLB, lRate, epochs, classesLB, featuresLB);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ΤΕΛΟΣ απαντήσεων για τα ερωτήματα 1,2,3"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}